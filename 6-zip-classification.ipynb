{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 8723199,
     "sourceType": "datasetVersion",
     "datasetId": 5234766
    }
   ],
   "dockerImageVersionId": 30732,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "os.environ['WANDB_API_KEY'] =  UserSecretsClient().get_secret(\"WANDB_API_KEY\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T20:59:02.236662Z",
     "iopub.execute_input": "2024-06-25T20:59:02.237168Z",
     "iopub.status.idle": "2024-06-25T20:59:02.511387Z",
     "shell.execute_reply.started": "2024-06-25T20:59:02.237124Z",
     "shell.execute_reply": "2024-06-25T20:59:02.510252Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Install dependencies\n!pip install wandb scikit-multilearn-ng scikit-learn\n\n# Login to wandb\n!wandb login",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T20:59:02.513432Z",
     "iopub.execute_input": "2024-06-25T20:59:02.513784Z",
     "iopub.status.idle": "2024-06-25T20:59:22.484815Z",
     "shell.execute_reply.started": "2024-06-25T20:59:02.513754Z",
     "shell.execute_reply": "2024-06-25T20:59:22.483496Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gzip\n",
    "from skmultilearn.adapt import MLkNN\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T20:59:22.486673Z",
     "iopub.execute_input": "2024-06-25T20:59:22.487130Z",
     "iopub.status.idle": "2024-06-25T20:59:23.564788Z",
     "shell.execute_reply.started": "2024-06-25T20:59:22.487073Z",
     "shell.execute_reply": "2024-06-25T20:59:23.563796Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "import wandb",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T20:59:23.568028Z",
     "iopub.execute_input": "2024-06-25T20:59:23.568687Z",
     "iopub.status.idle": "2024-06-25T20:59:24.133425Z",
     "shell.execute_reply.started": "2024-06-25T20:59:23.568647Z",
     "shell.execute_reply": "2024-06-25T20:59:24.132514Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Setup WANDB\nrun = wandb.init(\n    project='pms',\n    job_type='zip-test',\n    save_code=True,\n    name='zip-10',\n    config={\n    },\n)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T20:59:24.134874Z",
     "iopub.execute_input": "2024-06-25T20:59:24.135223Z",
     "iopub.status.idle": "2024-06-25T20:59:43.938603Z",
     "shell.execute_reply.started": "2024-06-25T20:59:24.135190Z",
     "shell.execute_reply": "2024-06-25T20:59:43.937506Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Micro averaged metrics, or per instance metrics\n",
    "\n",
    "def exact_match_ratio(y_true, y_pred, epoch):\n",
    "    exact_match_ratio_score = accuracy_score(y_true, y_pred)\n",
    "    print(f\"Epoch {epoch} - Exact Match Ratio: {exact_match_ratio_score}\")\n",
    "    run.summary[f\"exact_match_ratio_epoch_{epoch}\"] = exact_match_ratio_score\n",
    "\n",
    "\n",
    "def micro_accuracy(y_true, y_pred, epoch):\n",
    "    correctly_predicted_labels = np.logical_and(y_true, y_pred).sum(axis=1)  # Intersection of true and predicted labels\n",
    "    total_labels = np.logical_or(y_true, y_pred).sum(axis=1)  # Union of true and predicted labels   \n",
    "    instance_acc = correctly_predicted_labels / total_labels\n",
    "\n",
    "    average_accuracy = np.average(instance_acc)\n",
    "    print(f\"Epoch {epoch} - Overall Accuracy: {average_accuracy}\")\n",
    "    run.summary[f\"overall_accuracy_epoch_{epoch}\"] = average_accuracy\n",
    "\n",
    "\n",
    "def micro_precision(y_true, y_pred, epoch):\n",
    "    correctly_predicted_labels = np.logical_and(y_true, y_pred).sum(axis=1)  # | Y ∩ Z | in the formula \n",
    "    count_of_predicted_labels = y_pred.sum(axis=1)  # | Z | in the formula \n",
    "\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):  # Avoid division by zero\n",
    "        precision_per_instance = np.true_divide(correctly_predicted_labels, count_of_predicted_labels)\n",
    "        precision_per_instance[\n",
    "            count_of_predicted_labels == 0] = 0  # Set precision to 0 where there are no actual positives\n",
    "\n",
    "    average_precision = np.average(precision_per_instance)\n",
    "    print(f\"Epoch {epoch} - Overall Precision: {average_precision}\")\n",
    "    run.summary[f\"overall_precision_epoch_{epoch}\"] = average_precision\n",
    "\n",
    "\n",
    "def micro_recall(y_true, y_pred, epoch):\n",
    "    correctly_predicted_labels = np.logical_and(y_true, y_pred).sum(axis=1)  # | Y ∩ Z | in the formula\n",
    "    count_of_true_positives = y_true.sum(axis=1)  # | Y | in the formula\n",
    "\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):  # Avoid division by zero\n",
    "        recall_per_instance = np.true_divide(correctly_predicted_labels, count_of_true_positives)\n",
    "        recall_per_instance[count_of_true_positives == 0] = 0  # Set recall to 0 where there are no predicted positives\n",
    "\n",
    "    average_recall = np.average(recall_per_instance)\n",
    "    print(f\"Epoch {epoch} - Overall Recall: {average_recall}\")\n",
    "    run.summary[f\"overall_recall_epoch_{epoch}\"] = average_recall\n",
    "\n",
    "\n",
    "def micro_f1_score(y_true, y_pred, epoch):\n",
    "    true_positives = np.logical_and(y_true, y_pred).sum(axis=1)\n",
    "    total_actual_positives = y_true.sum(axis=1)\n",
    "    total_predicted_positives = y_pred.sum(axis=1)\n",
    "\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        f1_per_instance = 2 * true_positives / (total_actual_positives + total_predicted_positives)\n",
    "        f1_per_instance[np.isnan(f1_per_instance)] = 0  # Set F1 to 0 where there are no positives (actual or predicted)\n",
    "\n",
    "    average_f1 = np.average(f1_per_instance)\n",
    "\n",
    "    print(f\"Epoch {epoch} - Overall F1 Score: {average_f1}\")\n",
    "    run.summary[f\"overall_f1_score_epoch_{epoch}\"] = average_f1\n",
    "\n",
    "\n",
    "# Hamming loss shows error, lower is better\n",
    "def instance_hamming_loss(y_true, y_pred, epoch):\n",
    "    xor_result = np.logical_xor(y_true, y_pred)  # True if prediction is wrong\n",
    "\n",
    "    incorrect_predictions = np.sum(xor_result)  # Total number of incorrect predictions\n",
    "    print(f\"Total incorrect predictions: {incorrect_predictions}\")\n",
    "\n",
    "    total_labels = np.size(y_true)  # Total number of labels\n",
    "    print(f\"Total labels: {total_labels}\")\n",
    "    hamming_losses = incorrect_predictions / total_labels\n",
    "    average_hamming_loss = np.average(hamming_losses)\n",
    "\n",
    "    print(f\"Epoch {epoch} - Hamming Loss: {average_hamming_loss}\")\n",
    "    run.summary[f\"hamming_loss_epoch_{epoch}\"] = average_hamming_loss\n",
    "\n",
    "\n",
    "# Macro averaged metrics, or per label metrics\n",
    "\n",
    "def log_per_label_metric(metric_values, metric_name, genres, epoch):\n",
    "    for i, current_genre in enumerate(genres):\n",
    "        # TODO: maybe log this as a table\n",
    "        print(f\"Epoch {epoch} - Per Label {metric_name} {current_genre}: {metric_values[i]:.4f}\")\n",
    "        run.summary[f\"per_label_{metric_name}_{current_genre}_epoch_{epoch}\"] = metric_values[i]\n",
    "\n",
    "    log_per_label_metric_table(metric_values, metric_name, genres, epoch)\n",
    "\n",
    "\n",
    "def log_per_label_metric_table(metric_values, metric_name, genres, epoch):\n",
    "    table_rows = []\n",
    "\n",
    "    for i, current_genre in enumerate(genres):\n",
    "        row = [epoch, metric_name, current_genre, metric_values[i]]\n",
    "        table_rows.append(row)\n",
    "\n",
    "    table = wandb.Table(data=table_rows, columns=[\"Epoch\", \"Metric Name\", \"Genre\", \"Metric Value\"])\n",
    "\n",
    "    run.log({f\"per_label_{metric_name}_epoch_{epoch}\": table})\n",
    "\n",
    "\n",
    "def log_per_label_average(metric_values, metric_name, epoch):\n",
    "    average = np.average(metric_values)\n",
    "    print(f\"Per Label Average {metric_name} epoch {epoch}: {average:.4f}\")\n",
    "    run.summary[f\"per_label_average_{metric_name}_epoch_{epoch}\"] = average\n",
    "    run.summary[f\"per_label_average_{metric_name}\"] = average\n",
    "\n",
    "\n",
    "def label_based_accuracy(y_true, y_pred, epoch):\n",
    "    num_labels = y_true.shape[1]\n",
    "    _accuracy_per_label = []\n",
    "\n",
    "    for label_idx in range(num_labels):\n",
    "        correct_predictions = np.sum(y_true[:, label_idx] == y_pred[:, label_idx])\n",
    "        total_predictions = y_true.shape[0]\n",
    "\n",
    "        label_accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "        _accuracy_per_label.append(label_accuracy)\n",
    "\n",
    "    log_per_label_metric(_accuracy_per_label, 'Accuracy', INCLUDED_GENRES, epoch)\n",
    "    log_per_label_average(_accuracy_per_label, 'Accuracy', epoch)\n",
    "\n",
    "\n",
    "def precision_per_label(y_true, y_pred, epoch):\n",
    "    num_labels = y_true.shape[1]\n",
    "    _precision_per_label = []\n",
    "    for label_idx in range(num_labels):\n",
    "        true_positives = np.sum((y_pred[:, label_idx] == 1) & (y_true[:, label_idx] == 1))\n",
    "        false_positives = np.sum((y_pred[:, label_idx] == 1) & (y_true[:, label_idx] == 0))\n",
    "\n",
    "        label_precision = true_positives / (\n",
    "                true_positives + false_positives) if true_positives + false_positives > 0 else 0\n",
    "        _precision_per_label.append(label_precision)\n",
    "\n",
    "    log_per_label_metric(_precision_per_label, 'Precision', INCLUDED_GENRES, epoch)\n",
    "    log_per_label_average(_precision_per_label, 'Precision', epoch)\n",
    "\n",
    "\n",
    "def recall_per_label(y_true, y_pred, epoch):\n",
    "    num_labels = y_true.shape[1]\n",
    "    _recall_per_label = []\n",
    "    for label_idx in range(num_labels):\n",
    "        true_positives = np.sum((y_pred[:, label_idx] == 1) & (y_true[:, label_idx] == 1))\n",
    "        false_negatives = np.sum((y_pred[:, label_idx] == 0) & (y_true[:, label_idx] == 1))\n",
    "\n",
    "        label_recall = true_positives / (\n",
    "                true_positives + false_negatives) if true_positives + false_negatives > 0 else 0\n",
    "        _recall_per_label.append(label_recall)\n",
    "\n",
    "    log_per_label_metric(_recall_per_label, 'Recall', INCLUDED_GENRES, epoch)\n",
    "    log_per_label_average(_recall_per_label, 'Recall', epoch)\n",
    "\n",
    "\n",
    "def f1_score_per_label(y_true, y_pred, epoch):\n",
    "    num_labels = y_true.shape[1]\n",
    "    _f1_scores = []\n",
    "    for label_idx in range(num_labels):\n",
    "        true_positives = np.sum((y_pred[:, label_idx] == 1) & (y_true[:, label_idx] == 1))\n",
    "        false_positives = np.sum((y_pred[:, label_idx] == 1) & (y_true[:, label_idx] == 0))\n",
    "        false_negatives = np.sum((y_pred[:, label_idx] == 0) & (y_true[:, label_idx] == 1))\n",
    "\n",
    "        label_precision = true_positives / (\n",
    "                true_positives + false_positives) if true_positives + false_positives > 0 else 0\n",
    "        label_recall = true_positives / (\n",
    "                true_positives + false_negatives) if true_positives + false_negatives > 0 else 0\n",
    "\n",
    "        label_f1 = 2 * (label_precision * label_recall) / (label_precision + label_recall) if (\n",
    "                                                                                                      label_precision + label_recall) > 0 else 0\n",
    "        _f1_scores.append(label_f1)\n",
    "\n",
    "    log_per_label_metric(_f1_scores, 'F1', INCLUDED_GENRES, epoch)\n",
    "    log_per_label_average(_f1_scores, 'F1', epoch)\n",
    "\n",
    "\n",
    "# Calculate and log all metrics\n",
    "\n",
    "def calculate_and_log_metrics(true_values, predicted_values, _epoch):\n",
    "    # Exact match ratio\n",
    "    exact_match_ratio(true_values, predicted_values, _epoch)\n",
    "\n",
    "    # Micro averaged metrics\n",
    "    micro_accuracy(true_values, predicted_values, _epoch)\n",
    "    micro_precision(true_values, predicted_values, _epoch)\n",
    "    micro_recall(true_values, predicted_values, _epoch)\n",
    "    micro_f1_score(true_values, predicted_values, _epoch)\n",
    "    instance_hamming_loss(true_values, predicted_values, _epoch)\n",
    "\n",
    "    # Macro averaged metrics\n",
    "    label_based_accuracy(true_values, predicted_values, _epoch)\n",
    "    precision_per_label(true_values, predicted_values, _epoch)\n",
    "    recall_per_label(true_values, predicted_values, _epoch)\n",
    "    f1_score_per_label(true_values, predicted_values, _epoch)\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T20:59:43.940605Z",
     "iopub.execute_input": "2024-06-25T20:59:43.941018Z",
     "iopub.status.idle": "2024-06-25T20:59:44.678520Z",
     "shell.execute_reply.started": "2024-06-25T20:59:43.940980Z",
     "shell.execute_reply": "2024-06-25T20:59:44.677474Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "file_path = '/kaggle/input/movie-dataset-filtered/movies_metadata_filtered.csv'\n",
    "\n",
    "data = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "# convert transformed genres to list using ast\n",
    "data['genres'] = data['transformed_genres'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "data.head()\n",
    "\n",
    "train, temp = train_test_split(data, test_size=0.2, random_state=23)\n",
    "val, test = train_test_split(temp, test_size=0.5, random_state=23)\n",
    "\n",
    "data = pd.concat([train, val])\n",
    "\n",
    "GENRES_2 = ['Comedy', 'Drama', 'Documentary', 'Romance', 'Horror', 'Action', 'Thriller', 'Family', 'Adventure', 'Crime', 'Science Fiction']\n",
    "data['genres'] = data['genres'].apply(lambda x: [genre for genre in x if genre in GENRES_2])\n",
    "data = data[data['genres'].apply(len) > 0]\n",
    "train, val = train_test_split(data, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T20:59:44.679866Z",
     "iopub.execute_input": "2024-06-25T20:59:44.680280Z",
     "iopub.status.idle": "2024-06-25T20:59:46.645531Z",
     "shell.execute_reply.started": "2024-06-25T20:59:44.680244Z",
     "shell.execute_reply": "2024-06-25T20:59:46.644428Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "INCLUDED_GENRES = GENRES_2",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T20:59:46.646854Z",
     "iopub.execute_input": "2024-06-25T20:59:46.647190Z",
     "iopub.status.idle": "2024-06-25T20:59:47.391114Z",
     "shell.execute_reply.started": "2024-06-25T20:59:46.647163Z",
     "shell.execute_reply": "2024-06-25T20:59:47.389748Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "train['overview_compressed'] = train['overview'].apply(lambda x: len(gzip.compress(x.encode())))",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T20:59:47.394641Z",
     "iopub.execute_input": "2024-06-25T20:59:47.395317Z",
     "iopub.status.idle": "2024-06-25T20:59:49.214250Z",
     "shell.execute_reply.started": "2024-06-25T20:59:47.395279Z",
     "shell.execute_reply": "2024-06-25T20:59:49.212766Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def get_multilabel_data(overview):\n",
    "    # Standard gzip distance calculation\n",
    "    x1 = overview\n",
    "    cx1 = len(gzip.compress(x1.encode()))\n",
    "    distance_from_x1 = []\n",
    "\n",
    "    training_set_idx = []\n",
    "    genres_idx = []\n",
    "\n",
    "    for train_index, train_row in train.iterrows():\n",
    "        x2 = train_row.overview\n",
    "        cx2 = train_row.overview_compressed\n",
    "        x1x2 = \" \".join([x1, x2])\n",
    "        cx1x2 = len(gzip.compress(x1x2.encode()))\n",
    "        ncd = (cx1x2 - min(cx1 ,cx2)) / max(cx1 , cx2)\n",
    "        distance_from_x1.append(ncd)\n",
    "        training_set_idx.append(train_index)\n",
    "        genres_idx.append(train_row.genres)\n",
    "\n",
    "    return distance_from_x1, training_set_idx, genres_idx"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T20:59:49.218636Z",
     "iopub.execute_input": "2024-06-25T20:59:49.218989Z",
     "iopub.status.idle": "2024-06-25T20:59:50.035904Z",
     "shell.execute_reply.started": "2024-06-25T20:59:49.218959Z",
     "shell.execute_reply": "2024-06-25T20:59:50.034878Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "import time",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T20:59:50.038022Z",
     "iopub.execute_input": "2024-06-25T20:59:50.038485Z",
     "iopub.status.idle": "2024-06-25T20:59:50.743170Z",
     "shell.execute_reply.started": "2024-06-25T20:59:50.038437Z",
     "shell.execute_reply": "2024-06-25T20:59:50.741859Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def balanced_genre_sampling(df, first_target, second_target):\n",
    "    sampled_indices = []\n",
    "    genre_counts = df.explode('genres')['genres'].value_counts().sort_values()\n",
    "    print(genre_counts)\n",
    "    genre_to_indices = {genre: [] for genre in genre_counts.keys()}\n",
    "\n",
    "    for genre in genre_counts.index:\n",
    "        filtered_df = df[df['genres'].apply(lambda genres: genre in genres)]\n",
    "        print(\"Genre: \", genre)\n",
    "        for index, row in filtered_df.iterrows():\n",
    "            genres = row['genres']\n",
    "            \n",
    "            if len(genres) <= 1:\n",
    "                continue\n",
    "\n",
    "            if all(len(genre_to_indices[g]) < first_target for g in genres):\n",
    "                for g in genres:\n",
    "                    if len(genre_to_indices[g]) < first_target:\n",
    "                        genre_to_indices[g].append(index)\n",
    "                if index not in sampled_indices:\n",
    "                    sampled_indices.append(index)\n",
    "\n",
    "\n",
    "    second_pass_samples = []\n",
    "    for genre, indices in genre_to_indices.items():\n",
    "        if len(indices) < second_target:\n",
    "            single_genre_df = df[df.apply(lambda x: x['genres'] == [genre], axis=1)]\n",
    "            additional_samples = single_genre_df.sample(\n",
    "                min(second_target - len(indices), len(single_genre_df)), random_state=42\n",
    "            )\n",
    "            second_pass_samples.extend(additional_samples.index.tolist())\n",
    "\n",
    "    # Combine and remove duplicates\n",
    "    final_indices = list(set(sampled_indices + second_pass_samples))\n",
    "    final_sampled_df = df.loc[final_indices]\n",
    "\n",
    "    return final_sampled_df\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T20:59:50.744662Z",
     "iopub.execute_input": "2024-06-25T20:59:50.745063Z",
     "iopub.status.idle": "2024-06-25T20:59:51.454785Z",
     "shell.execute_reply.started": "2024-06-25T20:59:50.745027Z",
     "shell.execute_reply": "2024-06-25T20:59:51.453585Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "sampled_df = balanced_genre_sampling(val, 35, 30)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T20:59:51.455976Z",
     "iopub.execute_input": "2024-06-25T20:59:51.456869Z",
     "iopub.status.idle": "2024-06-25T20:59:53.125619Z",
     "shell.execute_reply.started": "2024-06-25T20:59:51.456838Z",
     "shell.execute_reply": "2024-06-25T20:59:53.124365Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "sampled_df",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T20:59:53.127206Z",
     "iopub.execute_input": "2024-06-25T20:59:53.127540Z",
     "iopub.status.idle": "2024-06-25T20:59:54.094028Z",
     "shell.execute_reply.started": "2024-06-25T20:59:53.127512Z",
     "shell.execute_reply": "2024-06-25T20:59:54.093023Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "sampled_df.explode('genres')['genres'].value_counts()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T20:59:54.095343Z",
     "iopub.execute_input": "2024-06-25T20:59:54.095645Z",
     "iopub.status.idle": "2024-06-25T20:59:54.855428Z",
     "shell.execute_reply.started": "2024-06-25T20:59:54.095620Z",
     "shell.execute_reply": "2024-06-25T20:59:54.854209Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "val_predictions = []\n",
    "val_predictions_binary = []\n",
    "counter = 0\n",
    "start_time = time.time()\n",
    "\n",
    "for idx, row in sampled_df.iterrows():\n",
    "    # calculate distances between current movie and all movies in training set\n",
    "    distances, rows, genres = get_multilabel_data(row.overview)\n",
    "\n",
    "    # prepare data\n",
    "    mlb = MultiLabelBinarizer(classes=GENRES_2)\n",
    "    y_train_binarized = mlb.fit_transform(genres)\n",
    "    x_train = np.array(distances).reshape(-1, 1)\n",
    "\n",
    "    # use scikit multilearn \n",
    "    mlknn = MLkNN(k=10)\n",
    "    mlknn.fit(x_train, y_train_binarized)\n",
    "\n",
    "    X_test = np.array([[0]])\n",
    "    y_pred = mlknn.predict(X_test)\n",
    "\n",
    "    predicted_genres = mlb.inverse_transform(y_pred)\n",
    "\n",
    "    y_pred = y_pred.toarray()[0]\n",
    "\n",
    "    val_predictions.append(predicted_genres)\n",
    "    val_predictions_binary.append(y_pred)\n",
    "    \n",
    "    counter += 1\n",
    "  \n",
    "    if counter == 1:\n",
    "        process_time = time.time() - start_time\n",
    "        print(f\"Time taken for 1 row: {process_time}\")\n",
    "        \n",
    "    if counter % 10 == 0:\n",
    "        print(\"processed 10th row\")\n",
    "    if counter == 100:\n",
    "        print(\"processed 100th row\")\n",
    "    if counter % 1000 == 0:\n",
    "        print(f\"Processed {counter} rows\")\n",
    "        break\n",
    "        \n",
    "# multilabel binarize dataframe of validation data\n",
    "mlb = MultiLabelBinarizer(classes=GENRES_2)\n",
    "val_genres_binarized = mlb.fit_transform(val['genres'])\n",
    "\n",
    "# print first val genres binarized\n",
    "print(val_genres_binarized[0])\n",
    "print(val_predictions_binary[0])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T20:59:54.856655Z",
     "iopub.execute_input": "2024-06-25T20:59:54.856953Z",
     "iopub.status.idle": "2024-06-25T21:51:21.028316Z",
     "shell.execute_reply.started": "2024-06-25T20:59:54.856929Z",
     "shell.execute_reply": "2024-06-25T21:51:21.027004Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "val_predictions_binary1 = np.array(val_predictions_binary)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T21:51:21.029803Z",
     "iopub.execute_input": "2024-06-25T21:51:21.030197Z",
     "iopub.status.idle": "2024-06-25T21:51:21.805909Z",
     "shell.execute_reply.started": "2024-06-25T21:51:21.030161Z",
     "shell.execute_reply": "2024-06-25T21:51:21.804735Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# ensure same length\n",
    "val_genres_binarized1 = val_genres_binarized[:len(val_predictions_binary1)]"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T21:51:21.807323Z",
     "iopub.execute_input": "2024-06-25T21:51:21.807707Z",
     "iopub.status.idle": "2024-06-25T21:51:22.609494Z",
     "shell.execute_reply.started": "2024-06-25T21:51:21.807675Z",
     "shell.execute_reply": "2024-06-25T21:51:22.608469Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "calculate_and_log_metrics(val_genres_binarized1, val_predictions_binary1, 0)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T21:51:22.610783Z",
     "iopub.execute_input": "2024-06-25T21:51:22.611185Z",
     "iopub.status.idle": "2024-06-25T21:51:24.288311Z",
     "shell.execute_reply.started": "2024-06-25T21:51:22.611151Z",
     "shell.execute_reply": "2024-06-25T21:51:24.287117Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "wandb.finish()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T21:51:24.290332Z",
     "iopub.execute_input": "2024-06-25T21:51:24.290748Z",
     "iopub.status.idle": "2024-06-25T21:51:41.022121Z",
     "shell.execute_reply.started": "2024-06-25T21:51:24.290712Z",
     "shell.execute_reply": "2024-06-25T21:51:41.020978Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
